{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#import google.generativeai as google\n",
    "\n",
    "file_path = \"data_clean.csv\"\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"filtered_tweets_engie.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "df = df.drop(['id', 'screen_name', 'name'], axis=1)\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], utc=True)\n",
    "df['created_at'] = df['created_at'].dt.tz_convert('Europe/Paris')\n",
    "df['created_at'] = df['created_at'].dt.strftime('%d/%m/%Y %Hh')\n",
    "\n",
    "#df.to_csv(\"data_clean.csv\", index=False, encoding=\"ISO-8859-1\", sep=\";\")\n",
    "df.to_json(\"data_clean.json\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mistralai in c:\\users\\gabri\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from mistralai) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from mistralai) (0.27.0)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from mistralai) (1.0.6)\n",
      "Requirement already satisfied: pydantic>=2.9.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from mistralai) (2.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabri\\appdata\\roaming\\python\\python312\\site-packages (from mistralai) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from mistralai) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->mistralai) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->mistralai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->mistralai) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->mistralai) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpx>=0.27.0->mistralai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->mistralai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->mistralai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->mistralai) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from pydantic>=2.9.0->mistralai) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabri\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\gabri\\anaconda3\\lib\\site-packages (from typing-inspect>=0.9.0->mistralai) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "üîπ Tweet 1 classified successfully.\n",
      "üîπ Tweet 2 classified successfully.\n",
      "üîπ Tweet 3 classified successfully.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 109\u001b[0m\n\u001b[0;32m     98\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     99\u001b[0m             {\n\u001b[0;32m    100\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m             }\n\u001b[0;32m    106\u001b[0m         )\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müîπ Tweet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classified successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pause for API rate limit\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# 5Ô∏è‚É£ Save Results to CSV\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# ================================\u001b[39;00m\n\u001b[0;32m    114\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%pip install mistralai\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "from mistralai import Mistral\n",
    "\n",
    "api_key = \"7AWeZFTcIqhdTArxPtAtENMQip622bPH\"\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "\n",
    "agent_id = \"ag:7c5f296e:20250310:untitled-agent:ef957914\"\n",
    "\n",
    "df = pd.read_csv(\"cleaned_filtered_tweets_engie.csv\", sep=\";\")\n",
    "df[\"created_at\"] = pd.to_datetime(\n",
    "    df[\"created_at\"], errors=\"coerce\", utc=True\n",
    ") \n",
    "\n",
    "if \"full_text\" not in df.columns:\n",
    "    raise ValueError(\"Error: Column 'full_text' not found in CSV.\")\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = text.translate(\n",
    "        str.maketrans(\"\", \"\", string.punctuation)\n",
    "    ) \n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "df[\"clean_text\"] = df[\"full_text\"].apply(clean_text)\n",
    "\n",
    "\n",
    "def classify_tweet_mistral(text):\n",
    "    prompt = f\"\"\"\n",
    "    You are an NLP agent for analyzing tweets.\n",
    "    Return **ONLY a valid JSON** with these attributes:\n",
    "\n",
    "    {{\n",
    "        \"category\": \"Facturation / Gaz / √âlectricit√© / Contrat / Autre\",\n",
    "        \"sentiment\": \"Positif / Neutre / N√©gatif\",\n",
    "        \"resolu\": \"Oui / Non\",\n",
    "        \"inconfort\": A score from 0 to 100,\n",
    "        \"urgence\": true / false\n",
    "    }}\n",
    "\n",
    "    Tweet: \"{text}\"\n",
    "\n",
    "    **Return only valid JSON output, no extra text.**\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.agents.complete(\n",
    "            agent_id=agent_id, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        json_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        json_text = json_text[json_text.find(\"{\") : json_text.rfind(\"}\") + 1]\n",
    "\n",
    "        return json_text \n",
    "    except Exception:\n",
    "        return \"Erreur\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tweet_text = df[\"clean_text\"].iloc[i]\n",
    "    result = classify_tweet_mistral(tweet_text)\n",
    "\n",
    "    try:\n",
    "        json_data = json.loads(result)\n",
    "        results.append(json_data)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format for tweet {i + 1}.\")\n",
    "        results.append(\n",
    "            {\n",
    "                \"category\": \"Erreur\",\n",
    "                \"sentiment\": \"Erreur\",\n",
    "                \"resolu\": \"Erreur\",\n",
    "                \"inconfort\": \"Erreur\",\n",
    "                \"urgence\": \"Erreur\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(f\"üîπ Tweet {i + 1} classified successfully.\")\n",
    "    time.sleep(5)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_final = df.head(len(df_results)).copy()\n",
    "df_final = pd.concat(\n",
    "    [df_final.reset_index(drop=True), df_results.reset_index(drop=True)], axis=1\n",
    ")\n",
    "\n",
    "df_final.to_csv(\"tweets_classified_kpi_mistral.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(\"‚úÖ Analysis complete! Results saved to 'tweets_classified_kpi_mistral.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
